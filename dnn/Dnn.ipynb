{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import TrainSetGen as trainingSG\n",
    "\n",
    "[training_data_coords, coords_A, coords_B] = trainingSG.getPoints()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60497f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_coords, coords_A, coords_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de77327e",
   "metadata": {},
   "outputs": [],
   "source": [
    "[phi1, phi2, phi3, phi4] = trainingSG.getAnglePhi(coords_A, coords_B)\n",
    "[theta1, theta2, theta3, theta4] = trainingSG.getAngleTheta(coords_A, coords_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038c5f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "phi1, phi2, phi3, phi4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be9d030",
   "metadata": {},
   "outputs": [],
   "source": [
    "theta1, theta2, theta3, theta4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eaf4943",
   "metadata": {},
   "outputs": [],
   "source": [
    "[w, doppler] = trainingSG.getWAndDoppler(\n",
    "    training_data_coords, theta1, theta2, theta3, theta4, phi1, phi2, phi3, phi4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2748def",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f09f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "doppler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3871db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import TestingSetGen as testingSG\n",
    "\n",
    "# 获取采样点\n",
    "x_points, y_points = testingSG.generate_modified_complex_curve()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83aee85",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_test = np.zeros([len(x_points)-1,4])\n",
    "for i in range(len(x_points)-2):\n",
    "    result_test[i][0]=x_points[i]\n",
    "    result_test[i][1]=y_points[i]\n",
    "    result_test[i][2]=x_points[i+1]\n",
    "    result_test[i][3]=y_points[i+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5afbd774",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import random\n",
    "# inputs_t = np.zeros([len(x_points)-1,6])\n",
    "\n",
    "# print(\"size of theta1=\", len(theta1))\n",
    "# print(\"size of phi1=\", len(phi1))\n",
    "# print(\"len(x_points)-2=\", len(x_points) - 2)\n",
    "\n",
    "# for i in range(len(x_points) - 2):\n",
    "#     x = result_test[i][0]\n",
    "#     y = result_test[i][1]\n",
    "#     x1 = result_test[i][2]\n",
    "#     y1 = result_test[i][3]\n",
    "#     d11 = calculate_distance(x,y,vertex1[0],vertex1[1])\n",
    "#     d12 = calculate_distance(x1,y1,vertex1[0],vertex1[1])\n",
    "#     d21 = calculate_distance(x,y,vertex2[0],vertex2[1])\n",
    "#     d22 = calculate_distance(x1,y1,vertex2[0],vertex2[1])\n",
    "#     d31 = calculate_distance(x,y,vertex3[0],vertex3[1])\n",
    "#     d32 = calculate_distance(x1,y1,vertex3[0],vertex3[1])\n",
    "#     d41 = calculate_distance(x,y,vertex3[0],vertex3[1])\n",
    "#     d42 = calculate_distance(x1,y1,vertex3[0],vertex3[1])\n",
    "    \n",
    "#     w12 = d11 * theta1[i] * (np.cos(phi1[i])+np.cos(phi2[i])) * fc / c * (theta1[i] * np.cos(phi1[i]) + np.sin(phi1[i]))\n",
    "#     w13 = d31 * theta3[i] * (np.cos(phi1[i])+np.cos(phi3[i])) * fc / c * (theta3[i] * np.cos(phi3[i]) + np.sin(phi3[i]))\n",
    "#     w14 = d41 * theta4[i] * (np.cos(phi1[i])+np.cos(phi3[i])) * fc / c * (theta4[i] * np.cos(phi4[i]) + np.sin(phi4[i]))\n",
    "\n",
    "#     v12 = v * fc * (np.cos(phi1[i]) + np.cos(phi2[i])) / c\n",
    "#     v13 = v * fc * (np.cos(phi1[i]) + np.cos(phi3[i])) / c\n",
    "#     v14 = v * fc * (np.cos(phi1[i]) + np.cos(phi4[i])) / c\n",
    "\n",
    "#     # dd12 = np.abs(d11+d21-d12-d22)\n",
    "#     # dd13 = np.abs(d11+d31-d12-d32)\n",
    "#     # w12 = 2*6*10e9*3.14*dd12/(3*10e8)\n",
    "#     # w13 = 2*6*10e9*3.14*dd13/(3*10e8)\n",
    "#     # v12 = (6*10e9/(3*10e8))*dd12*100\n",
    "#     # v13 = (6*10e9/(3*10e8))*dd13*100\n",
    "#     inputs_t[i][0] = w12\n",
    "#     inputs_t[i][1] = w13\n",
    "#     inputs_t[i][2] = w14\n",
    "#     inputs_t[i][3] = v12\n",
    "#     inputs_t[i][4] = v13\n",
    "#     inputs_t[i][5] = v14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd13f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "def pointInTriangle(pt, v1, v2, v3):\n",
    "    # Barycentric coordinates method\n",
    "    def sign(p1, p2, p3):\n",
    "        return (p1[0] - p3[0]) * (p2[1] - p3[1]) - (p2[0] - p3[0]) * (p1[1] - p3[1])\n",
    "\n",
    "    b1 = sign(pt, v1, v2) < 0.0\n",
    "    b2 = sign(pt, v2, v3) < 0.0\n",
    "    b3 = sign(pt, v3, v1) < 0.0\n",
    "\n",
    "    return ((b1 == b2) and (b2 == b3))\n",
    "\n",
    "# def triangleConstraintLoss(outputs, targets, v1, v2, v3):\n",
    "#     criterion = nn.MSELoss()\n",
    "    \n",
    "#     # 计算常规损失\n",
    "#     mse_loss = criterion(outputs, targets)\n",
    "    \n",
    "#     # 计算三角形约束损失\n",
    "#     constraint_loss = 0.0\n",
    "#     for output in outputs:\n",
    "#         # 如果点不在三角形内，增加损失\n",
    "#         if not pointInTriangle(output, v1, v2, v3):\n",
    "#             constraint_loss += 100.0\n",
    "\n",
    "#     # 总损失是常规损失和约束损失的和\n",
    "#     total_loss = mse_loss + constraint_loss\n",
    "#     return total_loss\n",
    "\n",
    "def triangleConstraintLoss(outputs, targets, v1, v2, v3):\n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    print(outputs.shape)\n",
    "    \n",
    "    # 计算常规损失\n",
    "    mse_loss = criterion(outputs, targets)\n",
    "    \n",
    "    # # 计算三角形约束损失\n",
    "    # constraint_loss = 0.0\n",
    "    # for output in outputs:\n",
    "    #     # 如果点不在三角形内，增加损失\n",
    "    #     if not pointInTriangle(output, v1, v2, v3):\n",
    "    #         constraint_loss += 100.0\n",
    "\n",
    "    # # 总损失是常规损失和约束损失的和\n",
    "    # total_loss = mse_loss + constraint_loss\n",
    "\n",
    "    d11 = outputs[0]\n",
    "    abs()\n",
    "    return total_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e001988",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "# 数据预处理\n",
    "inputs = np.concatenate((w, doppler), axis=1)  # 将 相位差和多普勒 拼接\n",
    "inputs_train, inputs_test, coords_train, coords_test = train_test_split(inputs, training_data_coords, test_size=0.1, random_state=42)\n",
    "\n",
    "# inputs_test = inputs_t\n",
    "# coords_test = result_test\n",
    "\n",
    "# 定义一个 PyTorch 数据集\n",
    "# 定义一个 PyTorch 数据集\n",
    "class CoordDataset(Dataset):\n",
    "    def __init__(self, inputs, coords):\n",
    "        # 确保 inputs 和 coords 都是 torch.float32 类型\n",
    "        self.inputs = torch.tensor(inputs, dtype=torch.float32)\n",
    "        self.coords = torch.tensor(coords, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.inputs[idx], self.coords[idx]\n",
    "# 创建训练和测试数据集\n",
    "train_dataset = CoordDataset(inputs_train, coords_train)\n",
    "test_dataset = CoordDataset(inputs_test, coords_test)\n",
    "\n",
    "# 创建 DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
    "\n",
    "# 定义更深的神经网络模型\n",
    "class DNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(6, 128)\n",
    "        self.fc2 = nn.Linear(128, 256)\n",
    "        self.fc3 = nn.Linear(256, 512)\n",
    "        self.fc4 = nn.Linear(512, 512)  # 新增层\n",
    "        self.fc5 = nn.Linear(512, 512)  # 新增层\n",
    "        self.fc6 = nn.Linear(512, 256)\n",
    "        self.fc7 = nn.Linear(256, 128)\n",
    "        self.fc8 = nn.Linear(128, 64)\n",
    "        self.fc9 = nn.Linear(64, 32)\n",
    "        self.fc10 = nn.Linear(32, 4)\n",
    "\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.tanh(self.fc1(x))\n",
    "        x = self.tanh(self.fc2(x))\n",
    "        x = self.tanh(self.fc3(x))\n",
    "        x = self.tanh(self.fc4(x))  # 新增层\n",
    "        x = self.tanh(self.fc5(x))  # 新增层\n",
    "        x = self.tanh(self.fc6(x))\n",
    "        x = self.tanh(self.fc7(x))\n",
    "        x = self.tanh(self.fc8(x))\n",
    "        x = self.tanh(self.fc9(x))\n",
    "        x = self.fc10(x)\n",
    "        return x\n",
    "\n",
    "# 使用GPU加速\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = DNN().to(device)\n",
    "\n",
    "# 损失函数和优化器\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0005)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# 训练模型\n",
    "# DER_MARK\n",
    "epochs = 1\n",
    "# epochs = 100\n",
    "\n",
    "loss_values = []  # 存储损失值以供绘图\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for inputs, coords in train_loader:\n",
    "        inputs, coords = inputs.to(device), coords.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, coords)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    loss_values.append(loss.item())\n",
    "\n",
    "    # 动态绘图\n",
    "    clear_output(wait=True)\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(loss_values, label='Loss')\n",
    "    plt.title('Loss Curve')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    # 打印损失信息\n",
    "    print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item()}')\n",
    "\n",
    "print(\"Testing...\")\n",
    "\n",
    "# 测试模型\n",
    "model.eval()\n",
    "total_test_loss = 0\n",
    "predicted_coords = []\n",
    "true_coords = []\n",
    "with torch.no_grad():\n",
    "    for inputs, coords in test_loader:\n",
    "        inputs, coords = inputs.to(device), coords.to(device)\n",
    "        outputs = model(inputs)\n",
    "        test_loss = criterion(outputs, coords)\n",
    "        # test_loss = triangleConstraintLoss(outputs, coords)\n",
    "        total_test_loss += test_loss.item()\n",
    "        predicted_coords.append(outputs.cpu().numpy())\n",
    "        true_coords.append(coords.cpu().numpy())\n",
    "\n",
    "# 合并所有批次的预测结果和真实值\n",
    "predicted_coords = np.concatenate(predicted_coords, axis=0)\n",
    "true_coords = np.concatenate(true_coords, axis=0)\n",
    "# 绘制散点图\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(true_coords[:, 0], true_coords[:, 1], label='True Coordinates', marker='o', s=30, alpha=0.7)\n",
    "plt.scatter(predicted_coords[:, 0], predicted_coords[:, 1], label='Predicted Coordinates', marker='x', s=30, alpha=0.7)\n",
    "plt.xlabel('X-coordinate')\n",
    "plt.ylabel('Y-coordinate')\n",
    "plt.legend()\n",
    "plt.title('True vs. Predicted Coordinates')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "print(f'Test Loss: {total_test_loss / len(test_loader)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb5ef3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6731b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 测试模型\n",
    "# model.eval()\n",
    "# total_test_loss = 0\n",
    "# predicted_coords = []\n",
    "# true_coords = []\n",
    "# with torch.no_grad():\n",
    "#     for inputs, coords in test_loader:\n",
    "#         inputs, coords = inputs.to(device), coords.to(device)\n",
    "#         outputs = model(inputs)\n",
    "#         test_loss = triangleConstraintLoss(outputs, coords, vertex1, vertex2, vertex3)\n",
    "#         total_test_loss += test_loss.item()\n",
    "#         predicted_coords.append(outputs.cpu().numpy())\n",
    "#         true_coords.append(coords.cpu().numpy())\n",
    "\n",
    "# # 合并所有批次的预测结果和真实值\n",
    "# predicted_coords = np.concatenate(predicted_coords, axis=0)\n",
    "# true_coords = np.concatenate(true_coords, axis=0)\n",
    "# # 绘制散点图\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.scatter(true_coords[:, 0], true_coords[:, 1], label='True Coordinates', marker='o', s=30, alpha=0.7)\n",
    "# plt.scatter(predicted_coords[:, 0], predicted_coords[:, 1], label='Predicted Coordinates', marker='x', s=30, alpha=0.7)\n",
    "# plt.xlabel('X-coordinate')\n",
    "# plt.ylabel('Y-coordinate')\n",
    "# plt.legend()\n",
    "# plt.title('True vs. Predicted Coordinates')\n",
    "# plt.grid(True)\n",
    "# plt.show()\n",
    "# print(f'Test Loss: {total_test_loss / len(test_loader)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f86ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(true_coords[:, 0], true_coords[:, 1], label='True Coordinates', marker='o', s=30, alpha=0.7)\n",
    "plt.scatter(predicted_coords[:, 0], predicted_coords[:, 1], label='Predicted Coordinates', marker='x', s=30, alpha=0.7)\n",
    "plt.xlabel('X-coordinate')\n",
    "plt.ylabel('Y-coordinate')\n",
    "plt.legend()\n",
    "plt.title('True vs. Predicted Coordinates')\n",
    "plt.grid(True)\n",
    "plt.xlim(65,115)\n",
    "plt.show()\n",
    "print(f'Test Loss: {total_test_loss / len(test_loader)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2acb6c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# 数据预处理\n",
    "inputs = np.concatenate((w, v), axis=1)  # 将 w 和 v 拼接\n",
    "inputs_train, inputs_test, coords_train, coords_test = train_test_split(inputs, training_data_coords, test_size=0.5, random_state=42)\n",
    "\n",
    "# inputs_test = inputs_t\n",
    "# coords_test = result_test\n",
    "\n",
    "# 定义一个 PyTorch 数据集\n",
    "# 定义一个 PyTorch 数据集\n",
    "class CoordDataset(Dataset):\n",
    "    def __init__(self, inputs, coords):\n",
    "        # 确保 inputs 和 coords 都是 torch.float32 类型\n",
    "        self.inputs = torch.tensor(inputs, dtype=torch.float32)\n",
    "        self.coords = torch.tensor(coords, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.inputs[idx], self.coords[idx]\n",
    "# 创建训练和测试数据集\n",
    "train_dataset = CoordDataset(inputs_train, coords_train)\n",
    "test_dataset = CoordDataset(inputs_test, coords_test)\n",
    "\n",
    "# 创建 DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "# 定义更深的神经网络模型\n",
    "class DNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(4, 128)\n",
    "        self.fc2 = nn.Linear(128, 256)\n",
    "        self.fc3 = nn.Linear(256, 512)\n",
    "        self.fc4 = nn.Linear(512, 512)  # 新增层\n",
    "        self.fc5 = nn.Linear(512, 512)  # 新增层\n",
    "        self.fc6 = nn.Linear(512, 256)\n",
    "        self.fc7 = nn.Linear(256, 128)\n",
    "        self.fc8 = nn.Linear(128, 64)\n",
    "        self.fc9 = nn.Linear(64, 32)\n",
    "        self.fc10 = nn.Linear(32, 4)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.relu(self.fc3(x))\n",
    "        x = self.relu(self.fc4(x))  # 新增层\n",
    "        x = self.relu(self.fc5(x))  # 新增层\n",
    "        x = self.relu(self.fc6(x))\n",
    "        x = self.relu(self.fc7(x))\n",
    "        x = self.relu(self.fc8(x))\n",
    "        x = self.relu(self.fc9(x))\n",
    "        x = self.fc10(x)\n",
    "        return x\n",
    "\n",
    "# 使用GPU加速\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = DNN().to(device)\n",
    "\n",
    "#考虑约束关系\n",
    "#两个接收机的圆相交点\n",
    "#计算A点和B点的距离差\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "[\n",
    "    \n",
    "]\n",
    "#分段训练 10000个点 收敛 学习率降低 步长变短 \n",
    "#增加数据点\n",
    "\n",
    "\n",
    "# 损失函数和优化器\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.00005)\n",
    "\n",
    "# 训练模型\n",
    "epochs = 1500\n",
    "for epoch in range(epochs):\n",
    "    for inputs, coords in train_loader:\n",
    "        inputs, coords = inputs.to(device), coords.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, coords)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item()}')\n",
    "\n",
    "# 测试模型\n",
    "model.eval()\n",
    "total_test_loss = 0\n",
    "predicted_coords = []\n",
    "true_coords = []\n",
    "with torch.no_grad():\n",
    "    for inputs, coords in test_loader:\n",
    "        inputs, coords = inputs.to(device), coords.to(device)\n",
    "        outputs = model(inputs)\n",
    "        test_loss = criterion(outputs, coords)\n",
    "        total_test_loss += test_loss.item()\n",
    "        predicted_coords.append(outputs.cpu().numpy())\n",
    "        true_coords.append(coords.cpu().numpy())\n",
    "\n",
    "# 合并所有批次的预测结果和真实值\n",
    "predicted_coords = np.concatenate(predicted_coords, axis=0)\n",
    "true_coords = np.concatenate(true_coords, axis=0)\n",
    "# 绘制散点图\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(true_coords[:, 0], true_coords[:, 1], label='True Coordinates', marker='o', s=30, alpha=0.7)\n",
    "plt.scatter(predicted_coords[:, 0], predicted_coords[:, 1], label='Predicted Coordinates', marker='x', s=30, alpha=0.7)\n",
    "plt.xlabel('X-coordinate')\n",
    "plt.ylabel('Y-coordinate')\n",
    "plt.legend()\n",
    "plt.title('True vs. Predicted Coordinates')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "print(f'Test Loss: {total_test_loss / len(test_loader)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644f3fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(true_coords[:1497, 0], true_coords[:1497, 1], label='True Coordinates', marker='o', s=30, alpha=0.7)\n",
    "plt.scatter(predicted_coords[:1497, 0], predicted_coords[:1497, 1], label='Predicted Coordinates', marker='x', s=30, alpha=0.7)\n",
    "plt.xlabel('X-coordinate')\n",
    "plt.ylabel('Y-coordinate')\n",
    "plt.legend()\n",
    "plt.title('True vs. Predicted Coordinates')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "print(f'Test Loss: {total_test_loss / len(test_loader)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982a7e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = 0\n",
    "d2 = 0\n",
    "for i in range(len(true_coords)-1):\n",
    "    x = true_coords[i, 0]\n",
    "    y = true_coords[i, 1]\n",
    "    x1 = predicted_coords[i, 0]\n",
    "    y1 = predicted_coords[i, 1]\n",
    "    d11 = calculate_distance(x,y,vertex1[0],vertex1[1])\n",
    "    d12 = calculate_distance(x1,y1,vertex1[0],vertex1[1])\n",
    "    d21 = calculate_distance(x,y,vertex2[0],vertex2[1])\n",
    "    d22 = calculate_distance(x1,y1,vertex2[0],vertex2[1])\n",
    "    d31 = calculate_distance(x,y,vertex3[0],vertex3[1])\n",
    "    d32 = calculate_distance(x1,y1,vertex3[0],vertex3[1])\n",
    "    dd12 = np.abs(d11+d21-d12-d22)\n",
    "    dd13 = np.abs(d11+d31-d12-d32)\n",
    "    d1 = d1+dd12\n",
    "    d2 = d2+dd13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094f109d",
   "metadata": {},
   "outputs": [],
   "source": [
    "d2/len(true_coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f399137",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
