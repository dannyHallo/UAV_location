{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a33034a",
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# import src.TrainSetGen2 as tsg\n",
    "import src.Config as cf\n",
    "from matplotlib.patches import Polygon\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def sign(p1, p2, p3):\n",
    "    return (p1[0] - p3[0]) * (p2[1] - p3[1]) - (p2[0] - p3[0]) * (p1[1] - p3[1])\n",
    "\n",
    "\n",
    "def point_in_triangle(v1, v2, v3, pt):\n",
    "    d1 = sign(pt, v1, v2)\n",
    "    d2 = sign(pt, v2, v3)\n",
    "    d3 = sign(pt, v3, v1)\n",
    "\n",
    "    has_neg = (d1 < 0) or (d2 < 0) or (d3 < 0)\n",
    "    has_pos = (d1 > 0) or (d2 > 0) or (d3 > 0)\n",
    "\n",
    "    return not (has_neg and has_pos)\n",
    "\n",
    "\n",
    "def point_in_boundary(vertex1, vertex2, vertex3, vertex4, point):\n",
    "    # check if point is in boundary\n",
    "    return point_in_triangle(vertex1, vertex2, vertex3, point) or point_in_triangle(vertex3, vertex2, vertex4, point)\n",
    "\n",
    "\n",
    "def get_random_sample_in_quad(vertex1, vertex2, vertex3, vertex4):\n",
    "    # Randomly choose one of the two triangles to place a point\n",
    "    if np.random.rand() < 0.5:\n",
    "        # Working with triangle 1 (p123)\n",
    "        base_point = vertex1\n",
    "        edge0 = vertex2 - vertex1\n",
    "        edge1 = vertex3 - vertex1\n",
    "    else:\n",
    "        # Working with triangle 2 (p234)\n",
    "        base_point = vertex2\n",
    "        edge0 = vertex3 - vertex2\n",
    "        edge1 = vertex4 - vertex2\n",
    "    # Generate random x, y in the range [0, 1]\n",
    "    x, y = np.random.rand(2)\n",
    "    # Ensure the random point (x, y) lies within the triangle\n",
    "    if x + y > 1:\n",
    "        x = 1 - x\n",
    "        y = 1 - y\n",
    "    # Calculate a random point within the selected triangle\n",
    "    return base_point + edge0 * x + edge1 * y\n",
    "\n",
    "\n",
    "angle_change_limit = 0.1\n",
    "a_b_distance = 0.05  # Distance from this A to this B\n",
    "\n",
    "\n",
    "def random_angle_change(original_angle, angle_change_tolerance):\n",
    "    # Generate a random angle change within the tolerance\n",
    "    ang = original_angle + (np.random.rand() - 0.5) * \\\n",
    "        2 * angle_change_tolerance\n",
    "\n",
    "    # Ensure the angle is within the range [0, 2pi]\n",
    "    if ang < 0:\n",
    "        ang += 2 * np.pi\n",
    "    if ang > 2 * np.pi:\n",
    "        ang -= 2 * np.pi\n",
    "    return ang\n",
    "\n",
    "\n",
    "def random_walk(angle_change_per_step, length_per_step, last_angle, last_coords_a):\n",
    "    this_angle = random_angle_change(last_angle, angle_change_per_step)\n",
    "    this_coords_a = last_coords_a + \\\n",
    "        np.array([np.cos(this_angle), np.sin(this_angle)]) * length_per_step\n",
    "    return [this_angle, this_coords_a]\n",
    "\n",
    "def get_coords_b(coords_a, angle):\n",
    "    return coords_a + np.array([np.cos(angle), np.sin(angle)]) * a_b_distance\n",
    "\n",
    "def create_line(num_points, line_length, angle_change_limit):\n",
    "    angle_change_per_step = angle_change_limit / num_points\n",
    "    length_per_step = line_length / num_points\n",
    "\n",
    "    # Start from a random point inside the boundary\n",
    "    starting_coords_a = get_random_sample_in_quad(\n",
    "        cf.vertex1, cf.vertex2, cf.vertex3, cf.vertex4)\n",
    "    starting_angle = np.random.rand() * 2 * np.pi\n",
    "\n",
    "    _angle = starting_angle\n",
    "    _coords_a = starting_coords_a\n",
    "\n",
    "    coords_a = [starting_coords_a]\n",
    "    coords_b = [get_coords_b(starting_coords_a, starting_angle)]\n",
    "\n",
    "    while True:\n",
    "        [_angle, _coords_a] = random_walk(\n",
    "            angle_change_per_step, length_per_step, _angle, _coords_a)\n",
    "\n",
    "        in_boundary = point_in_boundary(cf.vertex1, cf.vertex2, cf.vertex3, cf.vertex4, _coords_a)\n",
    "        if not in_boundary:\n",
    "            return [\n",
    "                coords_a,\n",
    "                coords_b,\n",
    "                False\n",
    "            ]\n",
    "\n",
    "        coords_a.append(_coords_a)\n",
    "        coords_b.append(get_coords_b(_coords_a, _angle))\n",
    "        \n",
    "        print(len(coords_a))\n",
    "        if len(coords_a) == num_points:\n",
    "            return [\n",
    "                coords_a,\n",
    "                coords_b,\n",
    "                True\n",
    "            ]\n",
    "\n",
    "# test and plot\n",
    "\n",
    "\n",
    "# cf.vertex1....\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_xlim(-300, 300)\n",
    "ax.set_ylim(-300, 300)\n",
    "ax.add_patch(\n",
    "    Polygon([cf.vertex1, cf.vertex2, cf.vertex3, cf.vertex4], fill=False))\n",
    "\n",
    "for point in test_points:\n",
    "    if point_in_boundary(cf.vertex1, cf.vertex2, cf.vertex3, cf.vertex4, point):\n",
    "        ax.plot(point[0], point[1], 'ro')\n",
    "    else:\n",
    "        ax.plot(point[0], point[1], 'bo')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9efde990",
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import src.Common as cm\n",
    "\n",
    "[train_w, train_doppler] = cm.getWAndDoppler(train_coords_A, train_coords_B)\n",
    "[test_w, test_doppler] = cm.getWAndDoppler(test_coords_A, test_coords_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728d86a1",
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import src.Config as cf\n",
    "\n",
    "vertex1 = np.array([0, 0])\n",
    "vertex2 = np.array([200, 0])\n",
    "vertex3 = np.array([100, 100])\n",
    "vertex4 = np.array([300, 150])\n",
    "\n",
    "vertices_position = np.concatenate((vertex1, vertex2, vertex3, vertex4))\n",
    "        \n",
    "train_position = np.full((cf.train_points_num, len(vertices_position)), vertices_position)\n",
    "test_position = np.full((cf.test_points_num, len(vertices_position)), vertices_position)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd13f44",
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# import torch.nn as nn\n",
    "\n",
    "# def pointInTriangle(pt, v1, v2, v3):\n",
    "#     # Barycentric coordinates method\n",
    "#     def sign(p1, p2, p3):\n",
    "#         return (p1[0] - p3[0]) * (p2[1] - p3[1]) - (p2[0] - p3[0]) * (p1[1] - p3[1])\n",
    "\n",
    "#     b1 = sign(pt, v1, v2) < 0.0\n",
    "#     b2 = sign(pt, v2, v3) < 0.0\n",
    "#     b3 = sign(pt, v3, v1) < 0.0\n",
    "\n",
    "#     return ((b1 == b2) and (b2 == b3))\n",
    "\n",
    "# def triangleConstraintLoss(outputs, targets, v1, v2, v3):\n",
    "#     criterion = nn.MSELoss()\n",
    "    \n",
    "#     # 计算常规损失\n",
    "#     mse_loss = criterion(outputs, targets)\n",
    "    \n",
    "#     # 计算三角形约束损失\n",
    "#     constraint_loss = 0.0\n",
    "#     for output in outputs:\n",
    "#         # 如果点不在三角形内，增加损失\n",
    "#         if not pointInTriangle(output, v1, v2, v3):\n",
    "#             constraint_loss += 100.0\n",
    "\n",
    "#     # 总损失是常规损失和约束损失的和\n",
    "#     total_loss = mse_loss + constraint_loss\n",
    "#     return total_loss\n",
    "\n",
    "# def triangleConstraintLoss(outputs, targets, v1, v2, v3):\n",
    "#     criterion = nn.MSELoss()\n",
    "    \n",
    "#     print(outputs.shape)\n",
    "    \n",
    "#     # 计算常规损失\n",
    "#     mse_loss = criterion(outputs, targets)\n",
    "    \n",
    "#     # # 计算三角形约束损失\n",
    "#     # constraint_loss = 0.0\n",
    "#     # for output in outputs:\n",
    "#     #     # 如果点不在三角形内，增加损失\n",
    "#     #     if not pointInTriangle(output, v1, v2, v3):\n",
    "#     #         constraint_loss += 100.0\n",
    "\n",
    "#     # # 总损失是常规损失和约束损失的和\n",
    "#     # total_loss = mse_loss + constraint_loss\n",
    "\n",
    "#     d11 = outputs[0]\n",
    "#     abs()\n",
    "#     return total_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18aefa37",
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "train_inputs = np.concatenate((train_w, train_doppler, train_position), axis=1)  # 将 相位差和多普勒 拼接\n",
    "test_inputs = np.concatenate((test_w, test_doppler, test_position), axis=1)  # 将 相位差和多普勒 拼接\n",
    "\n",
    "def normalize_first_n_columns(data, n):\n",
    "   # 计算前n列的最大值和最小值\n",
    "   min_vals = data[:, :n].min(axis=0)\n",
    "   max_vals = data[:, :n].max(axis=0)\n",
    "\n",
    "   # 归一化前n列\n",
    "   data[:, :n] = (data[:, :n] - min_vals) / (max_vals - min_vals)\n",
    "\n",
    "\n",
    "# normalize the first 6 columns\n",
    "# normalize_first_n_columns(train_inputs, 6)\n",
    "# normalize_first_n_columns(test_inputs, 6)\n",
    "\n",
    "# import numpy as np\n",
    "# train_other_inputs.fill(0)\n",
    "# test_other_inputs.fill(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789ebe83",
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "current_time = time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.localtime())\n",
    "result_folder = \"results/\" + current_time\n",
    "os.makedirs(result_folder)\n",
    "\n",
    "training_results_folder = result_folder + \"/training\"\n",
    "os.makedirs(training_results_folder)\n",
    "\n",
    "testing_results_folder= result_folder + \"/testing\"\n",
    "os.makedirs(testing_results_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e001988",
   "metadata": {
    "metadata": {},
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 定义更深的神经网络模型\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import src.Config as cf\n",
    "import src.CoordDataset as CoordDataset\n",
    "\n",
    "if(cf.using_model==\"dnn\"):\n",
    "    import src.DnnModel as DnnModel\n",
    "    using_model = DnnModel.DNN()\n",
    "elif(cf.using_model==\"rbf\"):\n",
    "    import src.RbfModel as RbfModel\n",
    "    using_model = RbfModel.RBFNetwork()\n",
    "else:\n",
    "    import src.TransformerModel as Transformer\n",
    "    using_model = Transformer.TransformerModel(input_size=14, hidden_size=128, output_size=4, num_layers=2, nhead=8, dropout=0.2)\n",
    "\n",
    "\n",
    "\n",
    "# 创建训练和测试数据集\n",
    "train_dataset = CoordDataset.CoordDataset(train_inputs, train_label)\n",
    "test_dataset = CoordDataset.CoordDataset(test_inputs, test_label)\n",
    "\n",
    "# 创建 DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=cf.train_batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=cf.test_batch_size, shuffle=False)\n",
    "\n",
    "# 使用GPU加速\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = using_model.to(device)\n",
    "\n",
    "for param in model.parameters():\n",
    "    print(type(param), param.size())\n",
    "\n",
    "# 损失函数和优化器s\n",
    "optimizer = optim.Adam(model.parameters(), lr=cf.learning_rate)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# 训练模型\n",
    "loss_values = []  # 存储损失值以供绘图\n",
    "\n",
    "for epoch in range(cf.epoch):\n",
    "    for inputs, coords in train_loader:\n",
    "        inputs, coords = inputs.to(device), coords.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, coords)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    loss_values.append(loss.item())\n",
    "\n",
    "    # 动态绘图\n",
    "    clear_output(wait=True)\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(loss_values, label=\"Loss\")\n",
    "    plt.title(\"Loss Curve\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.text(epoch, loss.item(), f\"Loss: {loss.item()}\", ha=\"right\")\n",
    "\n",
    "    train_result_name = training_results_folder + \"/up-to-date-loss.png\"\n",
    "    plt.savefig(train_result_name)\n",
    "    plt.show()\n",
    "\n",
    "    # 打印损失信息\n",
    "    print(f\"Epoch [{epoch+1}/{cf.epoch}], Loss: {loss.item()}\")\n",
    "\n",
    "    # 测试模型\n",
    "    model.eval()\n",
    "    total_test_loss = 0\n",
    "    predicted_coords = []\n",
    "    true_coords = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, coords in test_loader:\n",
    "            inputs, coords = inputs.to(device), coords.to(device)\n",
    "            outputs = model(inputs)\n",
    "            test_loss = criterion(outputs, coords)\n",
    "            total_test_loss += test_loss.item()\n",
    "            predicted_coords.append(outputs.cpu().numpy())\n",
    "            true_coords.append(coords.cpu().numpy())\n",
    "\n",
    "    # 合并所有批次的预测结果和真实值\n",
    "    predicted_coords = np.concatenate(predicted_coords, axis=0)\n",
    "    true_coords = np.concatenate(true_coords, axis=0)\n",
    "    # 绘制散点图\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(\n",
    "        true_coords[:, 0],\n",
    "        true_coords[:, 1],\n",
    "        label=\"True Coordinates\",\n",
    "        marker=\"o\",\n",
    "        s=30,\n",
    "        alpha=0.7,\n",
    "    )\n",
    "    plt.scatter(\n",
    "        predicted_coords[:, 0],\n",
    "        predicted_coords[:, 1],\n",
    "        label=\"Predicted Coordinates\",\n",
    "        marker=\"x\",\n",
    "        s=30,\n",
    "        alpha=0.7,\n",
    "    )\n",
    "    plt.xlabel(\"X-coordinate\")\n",
    "    plt.ylabel(\"Y-coordinate\")\n",
    "    plt.legend()\n",
    "    plt.title(\"True vs. Predicted Coordinates\")\n",
    "    plt.grid(True)\n",
    "    plt.text(\n",
    "        0,\n",
    "        0,\n",
    "        f\"Loss: {total_test_loss / len(test_loader)}\",\n",
    "        ha=\"left\",\n",
    "        va=\"bottom\",\n",
    "        transform=plt.gca().transAxes,\n",
    "    )\n",
    "    test_result_name = testing_results_folder + f\"/epoch-{epoch}-test-result.png\"\n",
    "    plt.savefig(test_result_name)\n",
    "    \n",
    "    plt.show()\n",
    "    print(f\"Test Loss: {total_test_loss / len(test_loader)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
